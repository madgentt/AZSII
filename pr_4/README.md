# Практика 4: Атака DeepFool на модели ИИ

Картунчиков Артем ББМО-01-23

# Цель задания:

Изучить атаку DeepFool, которая предназначена для минимальных изменений в изображениях с целью изменения их классификации. Научиться использовать эту атаку и исследовать влияние противоречивых примеров на обученные модели.

# Задачи:
1. Загрузить ранее обученную модель на датасете MNIST.
2. Изучить теоретические основы атаки DeepFool.
3. Реализовать атаку DeepFool с помощью фреймворка Foolbox.
4. Оценить точность модели на противоречивых примерах и сравнить с результатами на обычных данных.

# Вывод:
Точность модели на атакованных примерах резко снизилась до примерно 0%, особенно в сравнении с точностью на оригинальных данных, что зависит от параметров силы и количества шагов атаки.

Такое снижение точности указывает на неспособность модели справляться с задачей распознавания при наличии небольших, но целенаправленных искажений. Это подчеркивает важность разработки более устойчивых моделей и внедрения методов защиты от атак, чтобы повысить их надежность в реальных условиях.