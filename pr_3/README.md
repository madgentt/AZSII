# Практика 3: Атака Carlini-Wagner (CW) на модели ИИ

# Цель задания:
Изучить одну из наиболее мощных атак на модели ИИ — атаку Carlini-Wagner (CW). Задача — научиться использовать CW для создания противоречивых примеров и исследовать влияние этой атаки на обученные модели.

# Задачи:
1. Загрузить ранее обученную модель на датасете MNIST.
2. Изучить теоретические основы атаки Carlini-Wagner.
3. Реализовать атаку CW с помощью фреймворка Foolbox.
4. Оценить точность модели на противоречивых примерах и сравнить с результатами на обычных данных.

# Вывод:
Точность модели на атакованных примерах резко снизилась до примерно 7%, особенно в сравнении с точностью на оригинальных данных, что зависит от параметров силы и количества шагов атаки.

Такое снижение точности указывает на неспособность модели справляться с задачей распознавания при наличии небольших, но целенаправленных искажений. Это подчеркивает важность разработки более устойчивых моделей и внедрения методов защиты от атак, чтобы повысить их надежность в реальных условиях.