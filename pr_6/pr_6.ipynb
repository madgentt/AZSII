{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKl06fC8MqgR"
   },
   "source": [
    "# Практика 6: Атака по переносу (Transfer Attack) на модели ИИ\n",
    "\n",
    "Картунчиков Артем ББМО-01-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "# Нормализация данных\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "# Преобразование меток в one-hot encoding\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель 1: Простая полносвязная нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\artem\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model1 = Sequential([\n",
    "  Flatten(input_shape=(28, 28)),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(10, activation='softmax')])\n",
    "# Компиляция модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 982us/step - accuracy: 0.8773 - loss: 0.4358\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9661 - loss: 0.1177\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 968us/step - accuracy: 0.9767 - loss: 0.0741\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 969us/step - accuracy: 0.9832 - loss: 0.0544\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 999us/step - accuracy: 0.9876 - loss: 0.0398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])\n",
    "# Обучение модели\n",
    "model1.fit(train_images, train_labels, epochs=5)\n",
    "# Сохранение модели\n",
    "model1.save('mnist_model1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель 2: Свёрточная нейронная сеть (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\artem\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9088 - loss: 0.2919\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.0521\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0313\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9938 - loss: 0.0209\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential([\n",
    "  Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  MaxPooling2D((2, 2)),\n",
    "  Flatten(),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(10, activation='softmax')\n",
    "])\n",
    "# Компиляция модели\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])\n",
    "# Обучение модели\n",
    "model2.fit(train_images.reshape(-1, 28, 28, 1), train_labels, epochs=5)\n",
    "# Сохранение модели\n",
    "model2.save('mnist_model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация атаки FGSM на первую модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции для реализации FGSM атаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, gradient):\n",
    "  # Применение знака градиента к изображению\n",
    "  perturbed_image = image + epsilon * np.sign(gradient)\n",
    "  # Обрезка значений, чтобы они оставались в пределах [0,1]\n",
    "  perturbed_image = np.clip(perturbed_image, 0, 1)\n",
    "  return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adversarial_example(model, image, label, epsilon):\n",
    "    # Превращаем изображение в формат, подходящий для модели\n",
    "    image = tf.convert_to_tensor(image.reshape((1, 28, 28, 1)))\n",
    "\n",
    "    # Если label — это one-hot вектор, преобразуем его в индекс\n",
    "    if len(label.shape) > 1 and label.shape[1] > 1:\n",
    "        label = np.argmax(label)\n",
    "    label = tf.convert_to_tensor(label)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        prediction = model(image)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(label[None], prediction)\n",
    "\n",
    "    gradient = tape.gradient(loss, image)\n",
    "\n",
    "    # Применяем FGSM\n",
    "    adversarial_image = fgsm_attack(image.numpy(), epsilon, gradient.numpy())\n",
    "\n",
    "    # Убедимся, что adversarial_image имеет правильную форму\n",
    "    return np.reshape(adversarial_image, (28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adversarial_dataset(model, images, labels, epsilon):\n",
    "    adversarial_images = []\n",
    "    for i in range(len(images)):\n",
    "        adv_image = generate_adversarial_example(model, images[i], labels[i], epsilon)\n",
    "        adversarial_images.append(adv_image.reshape(28, 28))\n",
    "\n",
    "    adversarial_images = np.array(adversarial_images)\n",
    "\n",
    "    # Проверка формы\n",
    "    print(\"Shape of adversarial_images:\", adversarial_images.shape)\n",
    "\n",
    "    return adversarial_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация противоречивых примеров для первой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of adversarial_images: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.1\n",
    "adversarial_images_model1 = generate_adversarial_dataset(model1, test_images, test_labels, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка противоречивых примеров на обеих моделях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка первой модели на противоречивых примерах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.0985 - loss: 5.9598\n",
      "Accuracy of model1 on adversarial examples: 0.12929999828338623\n"
     ]
    }
   ],
   "source": [
    "loss1, acc1 = model1.evaluate(adversarial_images_model1, test_labels)\n",
    "print(f'Accuracy of model1 on adversarial examples: {acc1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка второй модели на противоречивых примерах (перенос атаки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9526 - loss: 0.1562\n",
      "Accuracy of model2 on adversarial examples from model1: 0.9617000222206116\n"
     ]
    }
   ],
   "source": [
    "adversarial_images_model1_reshaped = adversarial_images_model1.reshape(-1, 28, 28, 1)\n",
    "loss2, acc2 = model2.evaluate(adversarial_images_model1_reshaped, test_labels)\n",
    "print(f'Accuracy of model2 on adversarial examples from model1: {acc2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ переносимости атак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of adversarial_images: (10000, 28, 28)\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9297 - loss: 0.2365\n",
      "Accuracy of model1 on adversarial examples from model2: 0.9420999884605408\n"
     ]
    }
   ],
   "source": [
    "adversarial_images_model2 = generate_adversarial_dataset(model2,\n",
    "test_images.reshape(-1, 28, 28, 1), test_labels, epsilon)\n",
    "\n",
    "# Оценка первой модели на противоречивых примерах второй модели\n",
    "loss3, acc3 = model1.evaluate(adversarial_images_model2.reshape(-1, 28,\n",
    "28), test_labels)\n",
    "print(f'Accuracy of model1 on adversarial examples from model2: {acc3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "\n",
    "В ходе работы было исследовано влияние атаки переноса, при которой примеры, созданные для одной модели, использовались для атаки на другую. Для этой цели был применён метод FGSM (Fast Gradient Sign Method), позволяющий быстро генерировать искажающие примеры.\n",
    "\n",
    "Результаты эксперимента показали, что модель 1, на которой были созданы противоречивые примеры с использованием FGSM, продемонстрировала значительное снижение точности с 98% до 13%, что свидетельствует о её высокой уязвимости. Модель 2 оказалась гораздо более устойчивой, её точность снизилась всего на 4%, что указывает на её лучшую защиту от переноса атак.\n",
    "\n",
    "Атака переноса с применением FGSM может значительно ухудшить точность модели, особенно если примеры сгенерированы специально для неё. В то же время другая модель может оказаться менее подверженной таким атакам. Эти результаты подчёркивают важность разработки более устойчивых моделей, способных сохранять точность при атаке, перенесённой с другой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
