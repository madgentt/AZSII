# Практика 5: Атака с ограниченной памятью (PGD - Projected Gradient Descent)

Картунчиков Артем ББМО-01-23

# Цель задания:

Изучить одну из наиболее мощных атак на модели ИИ — атаку Projected Gradient Descent (PGD). Научиться использовать PGD для создания противоречивых примеров и оценить её влияние на обученные модели.

# Задачи:
 1. Загрузить ранее обученную модель на датасете MNIST.
 2. Изучить теоретические основы атаки PGD.
 3. Реализовать атаку PGD с помощью фреймворка Foolbox.
 4. Оценить точность модели на противоречивых примерах и сравнить с результатами на обычных данных.

# Вывод:
Точность модели на атакованных примерах снизилась до примерно 50%, по сравнению с точностью на оригинальных данных, в зависимости от параметров силы и количества шагов атаки.

Такое снижение точности свидетельствует о частичной уязвимости модели перед целенаправленными искажениями, созданными методом Projected Gradient Descent (PGD). Это подчеркивает необходимость разработки более устойчивых архитектур и методов защиты, чтобы повысить надежность модели в условиях реальных атак.